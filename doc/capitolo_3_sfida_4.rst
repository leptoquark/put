Sfida 4: Ruolo dei dati
-----------------------

Le tecniche e gli strumenti di Intelligenza Artificiale (IA) stanno oggi
beneficiando dell’enorme mole di dati che quotidianamente viene generata
da sistemi informatici. La qualità e l’interoperabilità di questi dati
rappresentano un fattore determinante per la possibilità stessa di
applicare le nuove tecnologie. Tra le principali tecniche di IA che
possono essere utilizzate per elaborare tali dati, ad esempio, vi è
quella del cosiddetto *supervised learning*. In questo caso, i dati
devono essere “annotati” dagli esseri umani che insegnano alle macchine
come interpretarli. Questa operazione è molto onerosa perché richiede
cospicuo e complesso lavoro umano. Oltre al lungo tempo necessario per
compiere tale lavoro di annotazione, la discrezionalità degli annotatori
potrebbe generare *dataset* disomogenei (ovvero: dati simili annotati in
maniera diversa), depotenziando il funzionamento delle macchine e
propagando errori.

La sfida associata al ruolo dei dati è dunque la creazione di
condizioni, anche organizzative, che consentano all’Intelligenza
Artificiale di utilizzare basi di dati costituite in maniera corretta,
dove siano garantite consistenza, qualità e intelligibilità.

Nel campo della *Internet of Things*, una delle principali sfide da
affrontare consiste nel fatto che i dati raccolti da dispositivi e
sensori interconnessi sono differenti da quelli con cui la comunità
scientifica dei *data scientist* ha dovuto misurarsi in passato. I più
grandi successi che sono stati conseguiti in ambito di IA riguardano,
infatti, applicazioni come l’elaborazione di immagini, la guida autonoma
e la ricerca sul *web* che sono stati resi possibili grazie alla
disponibilità di *dataset* ampi e relativamente strutturati, in grado
quindi di essere impiegati nell’addestramento degli algoritmi di
apprendimento automatico (*machine learning)*. Al contrario, i dati
provenienti da una moltitudine di dispositivi connessi fra loro possono
risultare frammentati, eterogenei e distribuiti irregolarmente nello
spazio e nel tempo: una sfida di rara complessità per chiunque aspiri ad
analizzare i dati in maniera strutturata.

Un secondo terreno di confronto è rappresentato dalla gestione e ricerca
dei dati pubblicati in rete sotto forma di *linked open data* [1]_.
Tali dati, che possono riguardare sia il compito istituzionale di un
ente pubblico (e.g. dati catastali o amministrativi) sia il suo
funzionamento (e.g. dati interni) sono resi accessibili e fruibili
mediante formati aperti. Pur rappresentando una miniera di informazioni,
i dati hanno bisogno di strumenti adeguati per poter essere sfruttati in
tutto il loro potenziale. In particolare, servono modelli e metodi di
recupero e filtraggio delle informazioni [2]_ fondati su tecnologie
semantiche e ontologie condivise. Questo lavoro, già previsto dal CAD e
avviato nell’ambito delle attività del Team Digitale, andrà inquadrato
nella prospettiva più ampia di una *governance* concettuale del
patrimonio informativo pubblico.

Una volta create le condizioni per il buon funzionamento delle
metodologie di Intelligenza Artificiale, uno dei compiti della Pubblica
amministrazione potrà essere quello di aggregare i dati necessari per
supportare il miglioramento dei processi. Questo potrebbe realizzarsi
attraverso la creazione di una piattaforma aperta per la raccolta,
generazione e gestione di alcune tipologie di dato, facente capo
direttamente alla Pubblica amministrazione [3]_. L’utilizzo
decentralizzato dei dataset pubblici, essenziale per lo sviluppo di
pratiche di partecipazione attiva (*civic activism*), richiede a sua
volta specifiche capacità di *governance* del sistema socio-tecnico
della Pubblica amministrazione. È fondamentale, infatti, che la qualità
dei dati sia assicurata alla fonte, mediante l’adozione generalizzata di
linee guida e di adeguati standard di contenuto.

Per raggiungere questi ambiziosi obiettivi, i temi da affrontare sono
molti, inclusi alcuni che compaiono già da anni nei piani di
*e-government* dei paesi sviluppati . Fra questi:

-  modalità di distribuzione e accesso ai dati;

-  progettazione e definizione di ontologie condivise;

-  supervisione della qualità dei dataset pubblici;

-  stima del valore economico attribuibile ai dati;

-  strumenti che consentano al cittadino di monitorare la produzione dei
   dati;

-  gestione e promozione dell’accesso ai dati [4]_;

-  regolamentazione dell’utilizzo dei dati [5]_.

Le ultime tre voci dell'elenco appena presentato introducono un
ulteriore tema per la PA: fare in modo che chiunque voglia sviluppare
soluzioni di Intelligenza Artificiale utili al cittadino possa avere un
accesso paritario e non discriminatorio ai dati necessari [6]_.

.. [1]
   Definizione di *Linked Open Data* *Cfr*.
   `https://www.w3.org/egov/wiki/Linked_Open_Data <https://www.w3.org/egov/wiki/Linked_Open_Data>`__.

.. [2]
   Information Retrieval: l’insieme delle tecniche utilizzate per il
   recupero mirato dell’informazione in formato elettronico. Per
   “informazione” si intendono tutti i documenti, i metadati, i file
   presenti all’interno di banche dati o nel www.

.. [3]
   *Cfr*.
   `https://pianotriennale-ict.readthedocs.io/it/latest/doc/09_data-analytics-framework.html <https://pianotriennale-ict.readthedocs.io/it/latest/doc/09_data-analytics-framework.html>`__.

.. [4]
   Si possono indire, per esempio, dei "grand challenge". Sono famosi
   quelli organizzati dal `NIST <https://www.nist.gov/>`__ su Speech
   Recognition e Machine Translation, da `DARPA sugli Autonomous
   Vehicles, <http://archive.darpa.mil/grandchallenge/>`__ o da
   `ImageNet <http://www.image-net.org/>`__ sulla Vision. Da questi
   challenge nascono prodotti o interi settori industriali. Un altro
   esempio molto interessante è quello di
   `HackDevelopers <https://hack.developers.italia.it/>`__, promosso dal
   team digitale.

.. [5]
   Cfr.
   `http://eur-lex.europa.eu/legal-content/en/TXT/?uri=CELEX%3A32016R0679 <http://eur-lex.europa.eu/legal-content/en/TXT/?uri=CELEX%3A32016R0679>`__.

.. [6]
   Sperequazioni che si sono verificate, per esempio, nel caso
   dell'accordo `tra il Royal Free London NHS Foundation Trust e Deep
   Mind di
   Googl <https://link.springer.com/article/10.1007/s12553-017-0179-1>`__ e
   per una sperimentazione dell'Intelligenza Artificiale del colosso
   informatico, nell'ambito della sanità britannica, con problemi
   sollevati in merito alla trasparenza e al trattamento dei dati
   sensibili.

.. discourse::
   :topic_identifier: 754
