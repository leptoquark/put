Sfida 7: Prevenire le disuguaglianze
------------------------------------

L’obiettivo di questa sfida è quello di approfondire le modalità con le
quali le tecnologie di Intelligenza Artificiale (IA) possano innescare
effetti positivi in termini di riduzione dei divari
socio/economico/culturali esistenti.

Diversi sono gli ambiti in cui l’inserimento di soluzioni di IA
consentirebbe di ridurre le diseguaglianze sociali. Fra questi si
citano:

-  istruzione e formazione;

-  conoscenza e garanzia dei diritti individuali;

-  sanità e disabilità, intesa come sostegno alle situazioni di disagio.

Nel settore scolastico è ipotizzabile un intervento significativo dei
sistemi intelligenti di supporto all’apprendimento. C’è una lunga
tradizione nell’uso del calcolatore per tali scopi: dai sistemi
*Computer Assisted Instruction* (CAI) ai sistemi *Intelligent Tutoring
Systems* (ITS). Negli ITS è sempre presente uno *student model* [1]_,
inteso come base di conoscenza in cui sono rappresentate in modo
esplicito le caratteristiche e le conoscenze dello studente. Questa
soluzione svolge un ruolo di sostegno fornendo un’integrazione ai
sistemi di insegnamento tradizionali, contribuendo a colmare le lacune
di apprendimento degli studenti con problemi cognitivi.

Un altro punto di intervento nel settore scolastico è rappresentato
dalla riduzione del *gap* linguistico. L’offerta di servizi di
traduzione simultanea adeguatamente modellati potrebbe aiutare a colmare
il divario generato dalle nuove ondate migratorie, offrendo dunque una
preziosa assistenza allo studio [2]_. Le tecnologie di Intelligenza
Artificiale potrebbero inoltre giocare un ruolo decisivo nella battaglia
contro l’analfabetismo funzionale [3]_.

L’IA, inoltre, potrebbe essere applicata per superare i limiti posti
dall’esigenza di possedere conoscenze specialistiche per svolgere
determinate attività. Sistemi di IA potrebbero diffondere l'accesso
all'informazione, alla conoscenza dei diritti e potrebbero facilitare le
modalità di esercizio degli stessi da parte dei soggetti che si trovano
in condizioni di disagio e che non hanno determinate conoscenze,
contribuendo in tal modo a ridurre le discriminazioni. Questo
rappresenta un importantissimo ambito di lavoro che richiede un adeguato
intervento di sensibilizzazione e di promozione culturale.

Per quanto riguarda il settore della disabilità, si evidenziano alcune
soluzioni interessanti in grado di garantire un accesso ai servizi più
facile e fruibile, migliorando così la qualità della vita degli
individui. È il caso, ad esempio, dei sintetizzatori vocali integrati al
pc per le persone ipovedenti, che potrebbero essere implementati con
programmi di redazione automatica in grado di ricordare le comunicazioni
precedenti e fornire bozze di testo, oppure di alcune sperimentazioni
che coinvolgono persone affette da malattie degenerative, come la SLA,
che forniscono sistemi di comunicazione atti a completare e facilitare
il processo comunicativo.

Volendo considerare tipologie di soluzioni di IA già note, l’utilizzo di
assistenti digitali potrebbe colmare in maniera trasversale i divari in
diverse categorie: ad esempio grazie all’IA problemi come la dislessia
potrebbero trovare un monitoraggio e un tentativo di correzione
attraverso l’uso di assistenti digitali che possono svolgere la funzione
del logopedista o dello psicologo.

La sfida sulle diseguaglianze va affrontata anche dal punto di vista
della necessità di non accrescere le diseguaglianze già esistenti.
Esistono due livelli di discriminazione potenziale, una che riguarda
l’accesso e l'uso delle tecnologie di IA e una indotta dagli stessi
sistemi di IA, basata sulla razza, sul sesso e altri fattori sociali.

È necessario operare per assicurare l’accesso a strumenti e soluzioni di
IA e la consapevolezza nel loro utilizzo, per evitare che possano fruire
dei benefici di queste tecnologie solo alcune categorie. In questo caso,
bisogna evitare di pensare che l’IA sia in sé un valore, soprattutto se
il suo utilizzo non è accompagnato da interventi idonei a ridurre la
possibilità che si creino ulteriori divari. Va inoltre evitato che siano
le stesse tecnologie di IA a comportare diseguaglianze.

Una PA legata al paradigma della responsabilità sociale non può
permettersi di creare situazioni in cui le modalità di contatto più
evolute, che tra l'altro sono quelle più semplici e che garantiscono una
maggiore accessibilità dei servizi, siano appannaggio esclusivo di
coloro che, per cultura, per propensione, per estrazione sociale o per
dotazione tecnologica siano maggiormente predisposti a tali
utilizzi [4]_.

È necessario che l’amministrazione usi grande cura nell’acquisire o
nell’indirizzare lo sviluppo delle soluzioni di IA al fine di garantire
che:

-  siano inclusive, accessibili, trasparenti e rispettino i requisiti di
   legge;

-  non presentino profili discriminatori;

-  siano esenti da pregiudizi (*bias*).

Negli ultimi tempi una delle aree di ricerca più attive nel campo
dell’IA è stata proprio quella dello studio dei *bias* sia dal punto di
vista statistico più formale che sotto un profilo legale e normativo più
ampio. In uno scenario positivo, i sistemi di IA possono essere
utilizzati per “aumentare”, migliorare il giudizio umano e ridurre i
nostri pregiudizi, consci o inconsci che siano. Tuttavia, dati,
algoritmi e altre scelte progettuali che possono influenzare i sistemi
di IA possono riflettere e amplificare le assunzioni culturali esistenti
in un dato momento storico e, di conseguenza, le disuguaglianze.

I *bias*, quindi, diventano la base per prendere decisioni, favorendo
alcuni scenari invece di altri, creando disparità e distribuzioni delle
opportunità non omogenee [5]_.

Per far questo, è necessario espandere le strategie di ricerca e
mitigazione dei bias non limitandole a un approccio strettamente
tecnico. I bias, per loro natura, costituiscono distorsioni strutturali
e di lungo termine che per essere fronteggiate necessitano di una
profonda ricerca interdisciplinare.

Affrontare e risolvere le criticità connesse ai *bias* richiede dunque
necessariamente una collaborazione interdisciplinare e metodi di ascolto
trasversali a diverse discipline [6]_.

Su questo terreno si gioca dunque la partita più importante per la
prevenzione delle diseguaglianze ed è in questo ambito che la Pubblica
amministrazione ha il compito di intervenire indirizzando lo sviluppo
delle soluzioni di IA, conscia dell’enorme potenziale che queste hanno
nella promozione di una più diffusa equità e nella riduzione dei divari
esistenti nella nostra società.

+-----------------------------------------------------------------------+
| Box                                                                   |
|                                                                       |
| Alcuni casi di *bias* che hanno avuto risalto recentemente:           |
|                                                                       |
| Un caso di **bias\discriminazione inconscia** è per esempio la        |
| percentuale di personale maschile che sviluppa servizi di IA rispetto |
| alla percentuale femminile (*Cfr*. `Global Gender Gap Report          |
| 2017 <https://assets.weforum.org/editor/AYpJgsnL2_I9pUhBQ7HII-erCJSEZ |
| 9dsC4eVn5Ydfck.png>`__,                                               |
| WEF).                                                                 |
|                                                                       |
| Altro caso, all’`interno dei tribunali                                |
| statunitensi <https://www.propublica.org/article/machine-bias-risk-as |
| sessments-in-criminal-sentencing>`__                                  |
| (Software utilizzato negli Stati Uniti con l’obiettivo di prevedere   |
| quali individui più di altri rischiano di essere “futuri criminali” - |
| ha messo in evidenza bias/pregiudizi nei confronti di individui di    |
| colore).                                                              |
|                                                                       |
| L’utilizzo estensivo di tecniche di **NLP** sta rapidamente mostrando |
| `quanto i vocabolari delle lingue più                                 |
| parlate <https://www.technologyreview.com/s/602025/how-vector-space-m |
| athematics-reveals-the-hidden-sexism-in-language/>`__,                |
| siano fortemente affetti da *bias* di genere.                         |
+-----------------------------------------------------------------------+

.. [1]
   Ioannis Panagiotopoulos, Aikaterini Kalou, Christos Pierrakeas,
   Achilles Kameas; An Ontology-Based Model for Student representation
   in Intelligent Tutoring Systems for Distance Learning, 2017
   Educational Content, Methodology and Technology Laboratory (e-CoMeT
   Lab) Hellenic Open University, Patras, Greece (Cfr.
   `https://hal.inria.fr/hal-01521391/document <https://hal.inria.fr/hal-01521391/document>`__
   - pag. 3).

.. [2]
   L'utilizzo dell’Intelligenza artificiale al servizio delle traduzioni
   automatiche è ormai diffuso (si pensi ai casi di Google, DeepL -
   *Cfr*.

   `http://www.repubblica.it/tecnologia/prodotti/2017/08/29/news/arriva_deepl_il_traduttore_automatico_che_sfida_google-174078830/ <http://www.repubblica.it/tecnologia/prodotti/2017/08/29/news/arriva_deepl_il_traduttore_automatico_che_sfida_google-174078830/>`__),
   a queste si affiancano in tempi più recenti i sistemi di traduzione
   istantanea e successiva sintesi vocale dei messaggi in una lingua
   desiderata (un esempio è quello del sistema attualmente in fase di
   sviluppo da parte di BabelOn Technologies - *Cfr*.
   `https://www.youtube.com/watch?v=sGdZsvLNuko <https://www.youtube.com/watch?v=sGdZsvLNuko>`__,
   oppure quello delle cuffie Google che permettono di tradurre
   all’istante ogni conversazione) che aprono interessanti prospettive
   di utilizzo in ambito scolastico.

.. [3]
   Per approfondimenti *Cfr*.
   `https://www.compareyourcountry.org/pisa/country/ITA?lg=en <https://www.compareyourcountry.org/pisa/country/ITA?lg=en>`__.

.. [4]
   Secondo l’art. 8 del Codice dell’Amministrazione Digitale (D.Lgs. n.
   82/20015), lo Stato e le pubbliche amministrazioni “*promuovono
   iniziative volte a favorire la diffusione della cultura digitale tra
   i cittadini con particolare riguardo ai minori e alle categorie a
   rischio di esclusione, anche al fine di favorire lo sviluppo di
   competenze di informatica giuridica e l'utilizzo dei servizi digitali
   delle pubbliche amministrazioni con azioni specifiche e concrete*”.

.. [5]
   Episodi di questo genere si sono verificati in molti casi: negli
   algoritmi di rating, di assegnazione dei lavori della *gig economy*
   e, in generale, nel lavoro mediato algoritmicamente.

.. [6]
   *Cfr*. AINOW 2017 Report, p. 2 “*Expand AI bias research and
   mitigation strategies beyond a narrowly technical approach*”.

.. discourse::
   :topic_identifier: 757
